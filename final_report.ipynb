{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms,models,datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from collections.abc import Iterable\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "FOLD = 1\n",
    "MAG = 40\n",
    "import cv2, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "%matplotlib inline\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Folds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class imagesXNN_train(Dataset):\n",
    "  def __init__(self, paths):\n",
    "    self.fpaths = paths\n",
    "\n",
    "  def __len__(self): return len(self.fpaths)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    f = self.fpaths[ix]\n",
    "    res = torch.tensor(int(\"malignant\" in f)).type(torch.LongTensor)\n",
    "    im = cv2.imread(f)[:,:,::-1]\n",
    "    return transforms.Compose([transforms.Resize((300, 300)), \n",
    "                               transforms.RandomHorizontalFlip(), \n",
    "                               transforms.RandomVerticalFlip()])(torch.tensor(im/255).permute(2,0,1).float()), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class imagesXNN_test(Dataset):\n",
    "  def __init__(self, paths):\n",
    "    self.fpaths = paths\n",
    "\n",
    "  def __len__(self): return len(self.fpaths)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    f = self.fpaths[ix]\n",
    "    res = torch.tensor(int(\"malignant\" in f)).type(torch.LongTensor)\n",
    "    im = cv2.imread(f)[:,:,::-1]\n",
    "    return transforms.Compose([transforms.Resize((300, 300))])(torch.tensor(im/255).permute(2,0,1).float()), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optim, local_metric_fn: Iterable):\n",
    "    local_metric = [0] * len(local_metric_fn)\n",
    "    local_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for step, (images, labels) in tqdm(enumerate(loader), total=312):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        local_loss = criterion(outputs, labels)\n",
    "        local_loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        local_loss += local_loss.item()\n",
    "        for i, metric in enumerate(local_metric_fn):\n",
    "            local_metric[i] += metric(outputs.cpu().detach().numpy().argmax(axis=1), labels.cpu().numpy())\n",
    "    return local_loss/(step + 1), [metric/(step + 1) for metric in local_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(model, loader, criterion, local_metric_fn: Iterable):\n",
    "    local_metric = [0] * len(local_metric_fn)\n",
    "    local_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    for step, (images, labels) in tqdm(enumerate(loader), total=187):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            local_loss = criterion(outputs, labels)\n",
    "            local_loss += local_loss.item()\n",
    "            for i, metric in enumerate(local_metric_fn):\n",
    "                local_metric[i] += metric(outputs.cpu().detach().numpy().argmax(axis=1), labels.cpu().numpy())\n",
    "    return local_loss/(step + 1), [metric/(step + 1) for metric in local_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, num_epochs, train_dl, valid_dl, loss_fn, optimizer, local_metric_fn, i=0, tolerance = 0.5):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        loss_tr_ep, metrics_tr_ep = train_epoch(model, train_dl, loss_fn, optimizer, local_metric_fn)\n",
    "\n",
    "        loss_hist_train[epoch] = loss_tr_ep\n",
    "        accuracy_hist_train[epoch] = metrics_tr_ep\n",
    "        \n",
    "        loss_ep, metrics_ep = valid_epoch(model, valid_dl, loss_fn, local_metric_fn)\n",
    "        \n",
    "        loss_hist_valid[epoch] = loss_ep\n",
    "        accuracy_hist_valid[epoch] = metrics_ep\n",
    "        if epoch == 0:\n",
    "            bestAccVal = accuracy_hist_valid[epoch][2]\n",
    "            torch.save(model.state_dict(), f'6models_fulldata_{i}_{FOLD}.pt')\n",
    "        else:\n",
    "            if accuracy_hist_valid[epoch][2] > max(bestAccVal, tolerance):\n",
    "                bestAccVal = accuracy_hist_valid[epoch][2]\n",
    "                torch.save(model.state_dict(), f'6models_fulldata_{i}_{FOLD}.pt')\n",
    "\n",
    "        print(f'Epoch {epoch+1} f1: {accuracy_hist_train[epoch][3]:{1}.{5}} val_f1: {accuracy_hist_valid[epoch][3]:{1}.{5}}')\n",
    "    if os.path.exists(f'6models_fulldata_{i}_{FOLD}.pt'):\n",
    "        model.load_state_dict(torch.load(f'6models_fulldata_{i}_{FOLD}.pt'))\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid, bestAccVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1 = df.loc[(df.fold==FOLD) & (df.mag==MAG) & (df.grp==\"train\")][\"filename\"].sample(frac=0.78).values\n",
    "fold2 = df.loc[(df.fold==FOLD) & (df.mag==MAG) & (df.grp==\"train\")][\"filename\"].sample(frac=0.78).values\n",
    "train_full = df.loc[(df.fold==FOLD) & (df.mag==MAG) & (df.grp==\"train\")][\"filename\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds_s1 = imagesXNN_train(fold1)\n",
    "trn_dl_s1 = DataLoader(trn_ds_s1, batch_size=2, shuffle=True, drop_last = True, num_workers = 0, pin_memory=True)\n",
    "\n",
    "trn_ds_s2 = imagesXNN_train(fold2)\n",
    "trn_dl_s2 = DataLoader(trn_ds_s2, batch_size=2, shuffle=True, drop_last = True, num_workers = 0, pin_memory=True)\n",
    "\n",
    "test_40 = imagesXNN_test(df.loc[(df.fold==FOLD) & (df.mag==MAG) & (df.grp==\"test\")][\"filename\"].values)\n",
    "test_dl = DataLoader(test_40, batch_size=4, shuffle=False, drop_last = True, num_workers = 0)\n",
    "\n",
    "trn_ds = imagesXNN_train(train_full)\n",
    "trn_dl = DataLoader(trn_ds, batch_size=4, shuffle=True, drop_last = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train single classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_v2_l(weights=models.EfficientNet_V2_L_Weights.DEFAULT)\n",
    "modelname=\"efficientnet_v2_l\"\n",
    "for layer in model.parameters():\n",
    "    layer.requires_grad = False\n",
    "model.classifier = nn.Sequential(nn.Linear(1280, 960), nn.ReLU(), nn.Dropout(0.2), nn.Linear(960, 540), nn.ReLU(), nn.Linear(540, 320), nn.ReLU(), nn.Linear(320, 100), nn.ReLU(), nn.Linear(100, 2), nn.Softmax(dim=1))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 1e-5)\n",
    "model = model.to(DEVICE)\n",
    "hst = train(model, 15, trn_dl, test_dl, loss_fn, optimizer,  [recall_score, precision_score, accuracy_score, f1_macro], i=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_b7(weights=models.EfficientNet_B7_Weights.DEFAULT)\n",
    "modelname=\"efficientnet_v1_b7\"\n",
    "model.classifier = nn.Sequential(nn.Linear(2560, 1560), nn.ReLU(), nn.Dropout(0.2), nn.Linear(1560, 960), nn.ReLU(), nn.Linear(960, 540), nn.ReLU(), nn.Linear(540, 320), nn.ReLU(), nn.Linear(320, 2), nn.Softmax(dim=1))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 1e-5)\n",
    "model = model.to(DEVICE)\n",
    "hst_v1b7 = train(model, 15, trn_dl, test_dl, loss_fn, optimizer,  [recall_score, precision_score, accuracy_score, f1_macro], i=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_constructor = [torchvision.models.efficientnet_v2_l(weights=torchvision.models.EfficientNet_V2_L_Weights.DEFAULT),\n",
    "                     torchvision.models.efficientnet_v2_m(weights=torchvision.models.EfficientNet_V2_M_Weights.DEFAULT),\n",
    "                     torchvision.models.efficientnet_v2_s(weights=torchvision.models.EfficientNet_V2_S_Weights.DEFAULT),\n",
    "                     torchvision.models.efficientnet_v2_l(),\n",
    "                     torchvision.models.efficientnet_v2_m(),\n",
    "                     torchvision.models.efficientnet_v2_s()\n",
    "                     ]\n",
    "\n",
    "\n",
    "\n",
    "def generate_model(i):\n",
    "    model = model_constructor[i]\n",
    "    model.classifier = nn.Sequential(nn.Linear(1280, 960), nn.Dropout(0.2, inplace=True), nn.ReLU(), nn.Linear(960, 480), nn.ReLU(), nn.Linear(480, 2))\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= 1e-5)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'centropy': loss,\n",
    "        'optimizer': optimizer,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [generate_model(j) for j in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.models = models\n",
    "\n",
    "    def forward(self, x):\n",
    "        preds = [models[\"model\"](x).detach().cpu().numpy() for models in self.models]\n",
    "        \n",
    "        preds_w = np.array(preds)\n",
    "        preds_w = nn.Softmax(dim=2)(torch.Tensor(preds_w)).numpy()\n",
    "        maxs = preds_w.max(axis=2)\n",
    "        maxs = nn.Softmax(dim=0)(torch.Tensor(maxs)).numpy()\n",
    "        amaxs = preds_w.argmax(axis=2) * 2 - 1\n",
    "        pred_w = (np.sum(maxs * amaxs, axis=0) > 0) * 1\n",
    "        \n",
    "\n",
    "        pred = np.array(preds)\n",
    "        y = pred.argmax(axis=2).sum(axis=0)/float(len(self.models))\n",
    "        return (y > 0.5)*1, pred_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    model[\"model\"].load_state_dict(torch.load(f'6models_fulldata_{i+1}_{FOLD}.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:25<00:00,  3.63it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 f1: 0.64005 val_f1: 0.77819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:25<00:00,  3.64it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 f1: 0.82407 val_f1: 0.75981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:30<00:00,  3.46it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 f1: 0.85466 val_f1: 0.80963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:27<00:00,  3.58it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 f1: 0.90527 val_f1: 0.81859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:27<00:00,  3.58it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 f1: 0.91752 val_f1: 0.83641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:57<00:00,  5.44it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 f1: 0.54231 val_f1: 0.67143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:59<00:00,  5.24it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 f1: 0.73094 val_f1: 0.77696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:59<00:00,  5.25it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 f1: 0.81564 val_f1: 0.82156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:01<00:00,  5.07it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 f1: 0.82769 val_f1: 0.82125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:57<00:00,  5.41it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 f1: 0.86969 val_f1: 0.77437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:46<00:00,  6.69it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 f1: 0.51978 val_f1: 0.66183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:45<00:00,  6.82it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 f1: 0.6409 val_f1: 0.65366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:45<00:00,  6.84it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 f1: 0.79092 val_f1: 0.66426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:43<00:00,  7.16it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 f1: 0.85919 val_f1: 0.68131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:43<00:00,  7.21it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 f1: 0.86021 val_f1: 0.76544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:25<00:00,  3.63it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 f1: 0.52022 val_f1: 0.65699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:25<00:00,  3.66it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 f1: 0.53567 val_f1: 0.67437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:33<00:00,  3.35it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 f1: 0.63443 val_f1: 0.71843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:25<00:00,  3.64it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 f1: 0.63396 val_f1: 0.69811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:24<00:00,  3.68it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 f1: 0.59478 val_f1: 0.6693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:25<00:00,  3.66it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 f1: 0.62196 val_f1: 0.63162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:26<00:00,  3.62it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 f1: 0.66378 val_f1: 0.67087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:26<00:00,  3.62it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 f1: 0.67874 val_f1: 0.68651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:25<00:00,  3.63it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 f1: 0.64655 val_f1: 0.67368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:25<00:00,  3.63it/s]\n",
      " 99%|█████████▉| 186/187 [00:19<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 f1: 0.67172 val_f1: 0.74921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:59<00:00,  5.26it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 f1: 0.52592 val_f1: 0.65699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:58<00:00,  5.33it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 f1: 0.5756 val_f1: 0.66109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:58<00:00,  5.29it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 f1: 0.62056 val_f1: 0.72243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:58<00:00,  5.36it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 f1: 0.63703 val_f1: 0.66687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:58<00:00,  5.33it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 f1: 0.67271 val_f1: 0.72071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:58<00:00,  5.34it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 f1: 0.65131 val_f1: 0.69747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:59<00:00,  5.24it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 f1: 0.65455 val_f1: 0.71224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:58<00:00,  5.34it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 f1: 0.67065 val_f1: 0.66477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:57<00:00,  5.40it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 f1: 0.67625 val_f1: 0.67384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:57<00:00,  5.39it/s]\n",
      " 99%|█████████▉| 186/187 [00:15<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 f1: 0.68362 val_f1: 0.72071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:44<00:00,  6.98it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 f1: 0.50943 val_f1: 0.65699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:44<00:00,  6.97it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 f1: 0.56838 val_f1: 0.72309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:44<00:00,  7.04it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 f1: 0.64666 val_f1: 0.72304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:44<00:00,  7.04it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 f1: 0.63158 val_f1: 0.71603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:44<00:00,  6.95it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 f1: 0.65737 val_f1: 0.71976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:43<00:00,  7.10it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 f1: 0.66065 val_f1: 0.69595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:45<00:00,  6.88it/s]\n",
      " 99%|█████████▉| 186/187 [00:14<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 f1: 0.65856 val_f1: 0.6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:45<00:00,  6.84it/s]\n",
      " 99%|█████████▉| 186/187 [00:14<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 f1: 0.69103 val_f1: 0.65059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:44<00:00,  6.97it/s]\n",
      " 99%|█████████▉| 186/187 [00:14<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 f1: 0.67262 val_f1: 0.58633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:43<00:00,  7.10it/s]\n",
      " 99%|█████████▉| 186/187 [00:13<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 f1: 0.69629 val_f1: 0.66293\n"
     ]
    }
   ],
   "source": [
    "epochs = [5,5,5,10,10,10]\n",
    "i = 0\n",
    "hist = []\n",
    "local_metric_fn = [recall_score, precision_score, accuracy_score, f1_macro]\n",
    "local_metric = [0] * len(local_metric_fn)\n",
    "for mdict, epoch in zip(models, epochs):\n",
    "    i += 1\n",
    "    hist.append(train(model = mdict[\"model\"], \n",
    "                        num_epochs= epoch, \n",
    "                        train_dl = trn_dl, \n",
    "                        valid_dl=test_dl, \n",
    "                        loss_fn=mdict[\"centropy\"], \n",
    "                        optimizer=mdict[\"optimizer\"], \n",
    "                        local_metric_fn=local_metric_fn,\n",
    "                        i=i)) \n",
    "scores = [i[4] for i in hist]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate ensemble output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6559139784946236, 0.5940860215053764, 0.8803763440860215, 0.8337941628264207]\n",
      "[0.6612903225806451, 0.6223118279569892, 0.8897849462365591, 0.8474142345110084]\n"
     ]
    }
   ],
   "source": [
    "ensemble = MyEnsemble(models)\n",
    "\n",
    "local_metric_fn = [recall_score, precision_score, accuracy_score, f1_macro]\n",
    "local_metric_simple = [0] * len(local_metric_fn)\n",
    "local_metric_conf = [0] * len(local_metric_fn)\n",
    "with torch.no_grad():\n",
    "    for step, (images, labels) in enumerate(test_dl):\n",
    "        images = images.to(DEVICE) \n",
    "        labels = labels.squeeze() \n",
    "        outputs = ensemble.forward(images)\n",
    "        for i, metric in enumerate(local_metric_fn):\n",
    "            local_metric_simple[i] += metric(outputs[0], labels)\n",
    "            local_metric_conf[i] += metric(outputs[1], labels)\n",
    "local_metric_simple = [metric/(step + 1) for metric in local_metric_simple]\n",
    "local_metric_conf = [metric/(step + 1) for metric in local_metric_conf]\n",
    "print(local_metric_simple)\n",
    "print(local_metric_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66129032 0.62231183 0.89247312 0.83640553]\n",
      "[0.66129032 0.62231183 0.89247312 0.83640553]\n",
      "[0.66129032 0.62231183 0.89247312 0.83640553]\n",
      "[0.66129032 0.62231183 0.89247312 0.83640553]\n",
      "[0.66129032 0.62231183 0.89247312 0.83640553]\n",
      "[0.66129032 0.62231183 0.89247312 0.83640553]\n"
     ]
    }
   ],
   "source": [
    "for model_hist in range(6):\n",
    "    print(np.array(hist[i][3]).max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-stacked ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, train_dl, valid_dl, loss_fn, optimizer, local_metric_fn, i=0, tolerance = 0.5):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        loss_tr_ep, metrics_tr_ep = train_epoch(model, train_dl, loss_fn, optimizer, local_metric_fn)\n",
    "\n",
    "        loss_hist_train[epoch] = loss_tr_ep\n",
    "        accuracy_hist_train[epoch] = metrics_tr_ep\n",
    "        \n",
    "        loss_ep, metrics_ep = valid_epoch(model, valid_dl, loss_fn, local_metric_fn)\n",
    "        \n",
    "        loss_hist_valid[epoch] = loss_ep\n",
    "        accuracy_hist_valid[epoch] = metrics_ep\n",
    "        if epoch == 0:\n",
    "            bestAccVal = accuracy_hist_valid[epoch][2]\n",
    "            torch.save(model.state_dict(), f'ensemble_3b0{i}_{FOLD}.pt')\n",
    "        else:\n",
    "            if accuracy_hist_valid[epoch][2] > max(bestAccVal, tolerance):\n",
    "                bestAccVal = accuracy_hist_valid[epoch][2]\n",
    "                torch.save(model.state_dict(), f'ensemble_3b0{i}_{FOLD}.pt')\n",
    "\n",
    "        print(f'Epoch {epoch+1} f1: {accuracy_hist_train[epoch][3]:{1}.{5}} val_f1: {accuracy_hist_valid[epoch][3]:{1}.{5}}')\n",
    "    if os.path.exists(f'ensemble_3b0{i}_{FOLD}.pt'):\n",
    "        model.load_state_dict(torch.load(f'ensemble_3b0{i}_{FOLD}.pt'))\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid, bestAccVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ensemble(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ensemble, self).__init__()\n",
    "        self.model1 = nn.Sequential(torchvision.models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).features,\n",
    "                                    torchvision.models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).avgpool)\n",
    "        self.model2 = nn.Sequential(torchvision.models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).features,\n",
    "                                    torchvision.models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).avgpool)\n",
    "        self.model3 = nn.Sequential(torchvision.models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).features,\n",
    "                                    torchvision.models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).avgpool)\n",
    "        self.model1 = self.model1.to(DEVICE)\n",
    "        self.model2 = self.model2.to(DEVICE)\n",
    "        self.model3 = self.model3.to(DEVICE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.model1(x)\n",
    "        out_test = torchvision.models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).features.to(DEVICE)(x)\n",
    "        out2 = self.model2(x)\n",
    "        out3 = self.model3(x)\n",
    "        cat = torch.concat((out1, out2, out3), dim = 1)\n",
    "        return nn.Sequential(nn.Flatten(),\n",
    "                             nn.Linear(1280*3, 960), \n",
    "                             nn.ReLU(), \n",
    "                             nn.Dropout(0.2), \n",
    "                             nn.Linear(960, 540), \n",
    "                             nn.ReLU(), \n",
    "                             nn.Linear(540, 320), \n",
    "                             nn.ReLU(), \n",
    "                             nn.Linear(320, 100), \n",
    "                             nn.ReLU(), \n",
    "                             nn.Linear(100, 2), \n",
    "                             nn.Softmax(dim=1)).to(DEVICE)(cat)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 1e-5)\n",
    "model = model.to(DEVICE)\n",
    "hst = train(model, 15, trn_dl, test_dl, loss_fn, optimizer,  [recall_score, precision_score, accuracy_score, f1_macro], i=11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
